Chapter 13: Team operations and experimentation
Video: Behind the product: Duolingo streaks | Jackson Shuttleworth (Group PM, Retention Team)
Time: 64:47 - 78:57
============================================================

We've done along the journey. I'm gonna shift to talking about how your team operates. There's a lot of threads you touch on about how a team can do this so well. Shift 600 experiments, as you said. Continue to find opportunity. What are some lessons or advice you'd have for folks that are like, "Oh, wow, I want to work more like this" from your team's experience? How do you use your team to operate that folks can learn?

Yeah, maybe just a little bit of context. Duolingo cares a lot about metrics. Most of our teams are metric-based teams. We do the most work with Streak, but the metric we really care about at the end of the day is Kerr and DAUs because we see that DAUs hit Kerr. When you can be really laser-focused on the goal each quarter to make this metric go up, I think it's much easier to ensure that you're working on the highest ROI thing. 

When you think more about like, "Oh, I want to make this feature better," it’s easier to get lost in what "better" means and how you think about better. So, having a really strong degree of focus as a team on what is the metric that I'm caring about and how is that directing my efforts versus being feature-oriented is crucial. Basically, your teams are structured around a metric, goal, or outcome versus owning a feature or product. Retention owns Streak, I guess, but that's only because we've seen Streak drive Kerr better than any feature. 

We are not against other teams working on the Streak because it’s not ours to say, "No, no, we do all the iterations here." We just know that it drives our metric better. In the same way that leaderboards work, we have a team that focuses on how much time users spend. We want users to spend more time on Duolingo so they're learning more. Leaderboards are the best vector for doing it. So that team does a lot of leaderboards work, but every now and then, I have an idea that I think will be highly retentive, and I will pitch it to them, and then we'll make some changes to the leaderboard to enhance retention. 

Having that clear metric of driving Kerr, not just making a feature better, helps give the team clear marching orders. That focus is really good for prioritizing the backlog. 

This is a really important point. This is the same way Airbnb worked when I was there for a long time. Here’s a goal that we want your team to be responsible for. You can work on any product you need to hit this goal. As you said, various products are most connected to what you're doing. But what you're describing is that even though teams kind of own it from a bug perspective, they are the shepherds of this part of the feature because it helps your goal the most. Any other team can come in and say, "Jackson, we need to work on some Streak stuff to help with learning." 

Does that mean they work closely with your team if they want to do some work in the code? How does that work?

If we're going to do something with the Streak, we probably have multiple quarters' worth of a roadmap around it. If other teams want to come and mess with it, we have to figure out how that’s going to work with our plans for the Streak. A lot of times when teams come in thinking, "Hey, let's do this to the Streak," they might not have the context that we do. So there's a knowledge-sharing aspect where we say, "Alright, this is what we think about the Streak. This is what we've seen work and hasn't worked. How does that influence some of the hypotheses that you have?" 

I think getting that really helps ensure that the juice is worth the squeeze. 

Another interesting aspect of how we operate is that my team lead, Antonia, runs a really process-oriented environment. If you're going to run this mini-experience, you have to be really thoughtful about which experiments to run and when. We have heavy Jira automation. Sometimes the Atlassian suite makes my eyes bleed, but that degree of process helps the team unblock engineers and make them move really fast. 

Making sure that you have a good process around how to run so many experiments is worth investing in. 

Can you follow that thread? What does that look like? What are some elements of that process to make this work efficiently?

It starts with detailed roadmaps. For example, this experiment is based on the results of this previous experiment or my hook into an element of this feature. We make sure that we're lining up implementation so that as soon as this thing runs and we're ready to go, we can start rolling out the next one. I hate features just sitting around, not continuing that thread. 

It's not just about thinking of engineering bandwidth but also design bandwidth to ensure that we have the next iteration of this feature ready. We’re planning months out as we think about these feature iterations, even small ones. When you lose cycles not pushing on a feature, it’s lost opportunity. So everything from being thoughtful about engineering roadmaps to design roadmaps to product roadmaps needs to come together in a system.

Essentially, mapping dependencies across functions, and you're saying in Jira, you can do this?

You can do a lot of it in Jira. There is a non-zero amount of Google Docs that we have that sometimes does things a little bit better. Sometimes it just looks a little nicer and is more flexible. But Jira is where the mother load of process is.

Great. What else?

Another thing I'll mention is that we really resist the urge to do the big V1. A lot of times when we're exploring something, we will say, "Okay, that's cool. How do we strip away a bunch of stuff and figure out what our core hypothesis is?" Then we just ship that thing first as a V1. 

It's easy to add things to features that make them win. I've worked in retention engagement long enough to know how to add bells and whistles to make something successful. But there are times when all the additions you made are not because of your core hypothesis. If you can simplify what the feature is, it's also much easier to ship and design. You’re not designing for a whole system; you’re designing for something much simpler. 

Getting everybody to think that way allows us to ship faster, design faster, get faster approval, gain insights, and then run iteration after iteration. By doing this, you not only move faster but also gain confidence at each step that your series of hypotheses is valid. If it’s not, you can drop that part of the feature and just ship what actually matters.

If I can summarize the broad lesson so far, it seems that you essentially map all the levers that drive the business. You have this mapping of all the metrics that drive growth and daily active users. Kerr ended up being the biggest specific metric to move to drive growth long-term. You found what is most connected to your growth and start exploring it. 

Once you find one, you go deep on trying a lot of different things. You come up with a hypothesis and a strategy for how you think you can move this, and then you just try a bunch of stuff. There’s also this element of the "there's always money in the banana stand" quote where you keep working on it, seeing there’s more opportunity. 

When I joined Duolingo, the PM I took over for, Anton, used to lead the retention team. I remember saying, "Dude, the Streak just counts up. You guys have been testing on it for years. How much more work can we do on the Streak?" He was like, "Jackson, you child." Four years later, I say that with conviction; we are still so far away from optimization. Every quarter, we ship a ton of wins and improvements to the Streak, proving that there is so much more to be done. 

I think your framing is important. There’s a lot of thought that goes into the strength of the hypotheses you have as you start to build out a larger future strategy. It’s really important to not just do random stuff but do it with intent and a goal in mind. Otherwise, you end up in these local maximas. 

Are there any other lasting lessons from this journey that you would recommend if someone were to try to operate this way and build streaks into their product?

I really think it starts with the understanding that streaks are an engagement hack. You can make your app more retentive. Almost every app can improve retention. It’s loss aversion; it's a human thing. But if your app is not something that users want to use every day, you're only going to get so much from that streak. Honestly, it’s probably going to distract you from what should matter: making your app something people want to use every day. 

If you start focusing on the streak without making that enjoyable experience, you're just wasting time. So, ensure that you have your core loop figured out and that it provides value to users. That really sets the stage for layering a streak on top. 

That’s a really good point. A streak is not going to solve your problems if people don't care about the core value you're providing.

No, and honestly, it’ll probably cause more problems. If you focus on making the streak highly engaging but your app isn’t, you're wasting time that could be better spent on solving more critical problems. 

Another thing I’ll mention is that we met with one of our board members, Bing Gordon, a few months ago. He commented that the reason users care about our streak so much is that Duolingo cares about the streak so much. After every session, you see a big streak screen, and it’s animated cooler than almost any other screen in the app. 

We don’t let users forget about it; we talk about it in messages. If you’re going to build a streak and then tuck it away in a corner of your app, users probably won’t care about it as much. If you want it to have the kind of impact that Duolingo has, it’s important to give it the visibility it deserves.

That’s such a good point. You look for cues in the app that tell you what to pay attention to. If you just have fireworks and explosions for a streak, maybe I should pay attention to this feature. Push notifications obviously encourage that too. 

Anything else along those lines?

The final thing is that we ran so many tests on our Duolingo streak to figure out what worked. We have a philosophy of testing first. We are often willing to test things. If you’re going to introduce a streak or improve on the one you have, don’t get too caught up in the philosophy of everything. 

Make sure your hypotheses feel solid, but my recommendation is to just try things. This is as much about human psychology as anything. As soon as that becomes the case, you need to understand what users respond to. The easiest way to do that is to stop spending time batting around ideas in a conference room and just try some stuff. So, a huge recommendation is that if you’re going to invest in a streak, figure out what works through testing with users rather than trying to get it perfect on the first try.